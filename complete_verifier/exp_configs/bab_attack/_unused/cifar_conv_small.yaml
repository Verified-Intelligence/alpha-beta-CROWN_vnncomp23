# MIP unsafe
# [4435]
# MIP unknown:
# [2053, 5962, 627, 5638, 97, 3224, 8534, 4534, 5131, 2528, 5479, 6696, 3899, 7356, 8971, 4107, 255, 7216, 320, 8610, 6587, 699, 7558, 3710, 8965, 6553, 658, 5453, 1556, 5702, 1099, 556, 9450, 178, 1606, 4958, 5602, 8540, 9912, 5567, 2011, 6662, 1033, 2073, 3375, 3292, 1946]
model:
  name: cifar_conv_small
  path: models/eran/cifar_conv_small_pgd.pth
data:
  dataset: CIFAR  # Dataset name. This is just the standard CIFAR-10 test set defined in the "load_verification_dataset()" function in utils.py
  mean: [0.4914, 0.4822, 0.4465]
  std: [0.2023, 0.1994, 0.201]
  start: 4435  # First example to verify in dataset. Only 7456 and 4024 (4024 can be attacked by PGD sometimes).
  end: 4436  # Last example to verify in dataset. We verify 100 examples in this test.
specification:
  norm: .inf  # Linf norm (can also be 2 or 1).
  epsilon: 0.00784313725  # 2./255.
attack:  # Currently attack is only implemented for Linf norm.
  pgd_steps: 100  # Increase for a stronger attack. A PGD attack will be used before verification to filter on non-robust data examples.
  pgd_restarts: 100  # Increase for a stronger attack.
  attack_mode: diverse_pgd
  pgd_order: before
solver:
  batch_size: 8192  # Number of subdomains to compute in parallel in beta-CROWN. Decrease if you run out of memory.
  alpha-crown:
    iteration: 100   # Number of iterations for alpha-CROWN optimization. Alpha-CROWN is used to compute all intermediate layer bounds before branch and bound starts.
    lr_alpha: 0.1    # Learning rate for alpha in alpha-CROWN. The default (0.1) is typically ok.
  beta-crown:
    lr_alpha: 0.01  # Learning rate for optimizing the alpha parameters, the default (0.01) is typically ok, but you can try to tune this parameter to get better lower bound.
    lr_beta: 0.05  # Learning rate for optimizing the beta parameters, the default (0.05) is typically ok, but you can try to tune this parameter to get better lower bound.
    lr_decay: 0.99
    iteration: 100  # Number of iterations for beta-CROWN optimization. 20 is often sufficient, 50 or 100 can also be used.
  mip:
    parallel_solvers: 8
    solver_threads: 1
bab:
  timeout: 1800  # Timeout threshold for branch and bound. Increase for verifying more points.
  max_domains: 5000000
  get_upper_bound: true  # Needed for Bab-Attack.
  attack:
    enabled: true
    beam_candidates: 32
    beam_depth: 8
    max_dive_fix_ratio: 0.3
    min_local_free_ratio: 0.4
    mip_timeout: 360
    mip_start_iteration: 2
    refined_mip_attacker: true
  branching:  # Parameters for branching heuristics.
    reduceop: max  # Reduction function for the branching heuristic scores, min or max. Using max can be better on some models.
    method: kfsb  # babsr is fast but less accurate; fsb is slow but most accurate; kfsb is usualy a balance.
    candidates: 3  # Number of candidates to consider in fsb and kfsb. More leads to slower but better branching. 3 is typically good enough.
